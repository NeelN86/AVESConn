{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1nWdqhbLhrIjTpcWjKu_AgSp-je_x1DzA",
      "authorship_tag": "ABX9TyOB7ZoNntE2wzDDNDSTiQug",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeelN86/AVESConn/blob/main/Copy_of_AvesConnectBackEnd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YsjgIhBfuAc"
      },
      "outputs": [],
      "source": [
        "# I utilized Anvil for the front-end of this side, not required but I found success with it\n",
        "!pip install anvil-uplink\n",
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(\"specific-server-code\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import needed libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BWCBqO-_i4TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install whatever database you want to use\n",
        "url='/url-to-whatever-database-you-want-to-use.csv'\n",
        "df=pd.read_csv(url)"
      ],
      "metadata": {
        "id": "afFTDkF-kx4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean up your data, in my example I filled up any null values with \"None\"\n",
        "df['What is your current job/profession?'] = df['What is your current job/profession?'].fillna('None')\n",
        "df['What are your favorite memories from your time at Sycamore?'] = df['What are your favorite memories from your time at Sycamore?'].fillna('None')\n"
      ],
      "metadata": {
        "id": "KZQCqBluBkya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install Transformers\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "uc-5NE_HlXjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import Tokenizer Model to turn individual into embeddings\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "8Kpl1W27l6q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-trained models, can be found online through huggingface\n",
        "tokenizer=AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "model=AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "NBPCTC-HmH-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# created a function to create word embeddings\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n"
      ],
      "metadata": {
        "id": "qUGO2l_noPEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaned up data even more by comnbining name and email\n",
        "df['Name']=df['Name']+' '+df['Email']"
      ],
      "metadata": {
        "id": "8adoUn8dV7vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# body of avesConnect function, create a dictionary for the final results\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "@anvil.server.callable\n",
        "def avesConnect(potentialStudent):\n",
        "    results = {}\n",
        "    student_embeddings = []\n",
        "    # tokenizes the student's inputted information and adds this to a list\n",
        "    for n in potentialStudent:\n",
        "        encoded_input = tokenizer(n, padding=True, truncation=True, return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            model_output = model(**encoded_input)\n",
        "        embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "        student_embeddings.append(embedding)\n",
        "\n",
        "    for x in range(len(df)):\n",
        "        attributes = ['What did you do after high school? Be specific. \\n(ex. if you went to college, where did you go, what did you major in, etc.)',\n",
        "                      'What is your current job/profession?',\n",
        "                      'What are your favorite memories from your time at Sycamore?']\n",
        "\n",
        "        alumni_embeddings = []\n",
        "        # tokenizes the alumni information in the dataset using the tokenizing function created earlier, then adds to these values to a list\n",
        "        for attr in attributes:\n",
        "            encoded_attribute = tokenizer(df[attr][x], padding=True, truncation=True, return_tensors='pt')\n",
        "            with torch.no_grad():\n",
        "                output = model(**encoded_attribute)\n",
        "            embedding = mean_pooling(output, encoded_attribute['attention_mask'])\n",
        "            alumni_embeddings.append(embedding)\n",
        "\n",
        "        overall_similarities = []\n",
        "        # utilized cosine similarity to determine how much of a match the student is with each alumni, adds each similarity value to a list\n",
        "        for i in range(len(potentialStudent)):\n",
        "            similarity = F.cosine_similarity(student_embeddings[i], alumni_embeddings[i], dim=1)\n",
        "            overall_similarities.append(similarity)\n",
        "\n",
        "        # Stack the cosine similarity scores along dim=1 and compute the sum for each individual\n",
        "        stacked_cos_similarities = torch.stack(overall_similarities, dim=1)\n",
        "        overallsimilarity = torch.sum(stacked_cos_similarities, dim=1)\n",
        "\n",
        "        results[df['Name'][x]] = overallsimilarity.mean().item()\n",
        "\n",
        "   # sort the results to include the 10 highest similarity scores, create a list for them, and then reveal the answer\n",
        "    sortedresults = sorted(results.items(), key=lambda z: z[1], reverse=True)\n",
        "    names=[]\n",
        "    for a in range(10):\n",
        "      names.append(sortedresults[a][0])\n",
        "    return names\n"
      ],
      "metadata": {
        "id": "kM6Q5gI8wF88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anvil.server.wait_forever()"
      ],
      "metadata": {
        "id": "E2aI3jnSoDgw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}